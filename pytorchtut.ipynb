{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import torch # Tensor Package (for use on GPU)\n",
    "import torch.nn as nn ## Neural Network package\n",
    "import torch.nn.functional as F # Non-linearities package\n",
    "import torch.optim as optim # Optimization package\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader # for dealing with data\n",
    "import torchvision # for dealing with vision data\n",
    "import torchvision.transforms as transforms # for modifying vision data to run it through models\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  Introduction\n",
    "\n",
    "Links:\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html - Pytorch's Tensor Tutorial\n",
    "\n",
    "https://pytorch.org/docs/stable/index.html - Pytorch's documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Tensor Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a one dimensional array the pytorch way (i.e. allowing GPU computations):\n",
    "x1 = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# here's a two dimensional array (i.e. of size 2 x 4):\n",
    "x2 = torch.tensor([[5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "\n",
    "# here's a three dimensional array (i.e. of size 2 x 2 x 4):\n",
    "x3 = torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor(1.)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# x1\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x1[0])\n",
    "print(\"----------------------------------------\")\n",
    "# prints tensor(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single element from tensor is a zero dimension tensor and not a python primitive like in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor(5)\n",
      "----------------------------------------\n",
      "tensor([5, 6, 7, 8])\n",
      "----------------------------------------\n",
      "tensor([ 7, 11])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# x2\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x2[0, 0]) \n",
    "\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x2[0, :]) \n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x2[:, 2])\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor(1)\n",
      "----------------------------------------\n",
      "tensor([1, 9])\n",
      "----------------------------------------\n",
      "tensor([1, 5])\n",
      "----------------------------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# x3\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x3[0, 0, 0]) \n",
    "# prints 1.0; the first entry of the first vector of the first set of vectors\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x3[:, 0, 0]) \n",
    "# prints 1, 9; the first entry of each first vector in each set of vectors\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x3[0, :, 0]) \n",
    "# prints 1, 5; pick the first set of vectors, and from each vector, choose the first entry\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x3[0, 0, :]) \n",
    "print(\"----------------------------------------\")\n",
    "# prints 1, 2, 3, 4; everything in the first vector of the first set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "# tensor with requires_grad set to True so we can use it for training and other stuff later\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(x)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(z, out)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "out.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)  Basic Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "[('weight', Parameter containing:\n",
      "tensor([[ 0.4952, -0.0880, -0.3639, -0.4884]], requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([0.1374], requires_grad=True))]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# x is a single datapoint\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "# create a linear layer (i.e. a linear equation: w1x1 + w2x2 + w3x3 + w4x4 + b, with 4 inputs and 1 output)\n",
    "# w and b stand for weight and bias, respectively\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "print(\"----------------------------------------\")\n",
    "print(list(linear_layer1.named_parameters()))\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor([-2.5887], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predicted_y = linear_layer1(x)\n",
    "# run the datapoint x through the linear equation and put the output in predicted_y\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(predicted_y)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3)  Calculating The Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor([0.0570], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "\n",
    "# ideally, we want our model to predict 0 when we input our x1 variable below.\n",
    "target_y = torch.tensor([0.0])\n",
    "\n",
    "\n",
    "predicted_y = linear_layer1(x)\n",
    "print(\"----------------------------------------\")\n",
    "print(predicted_y)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "loss = loss_function(predicted_y, target_y)\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(loss)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4)  Recalculating/Updating Our Weights (using gradient of loss wrt weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Weights (before update):\n",
      "Parameter containing:\n",
      "tensor([[-0.2039,  0.0166, -0.2483,  0.1886]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4260], requires_grad=True)\n",
      "----------------------------------------\n",
      "Weights (after update):\n",
      "Parameter containing:\n",
      "tensor([[-0.0864,  0.2516,  0.1042,  0.6586]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3085], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Now, we're going to calculate the gradient of our loss function wrt our weights / biases\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "\n",
    "target_y = torch.tensor([0.0])\n",
    "\n",
    "predicted_y = linear_layer1(x)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "loss = loss_function(predicted_y, target_y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# now that we have computed the gradient, let's look at our weights before we change them:\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Weights (before update):\")\n",
    "print(linear_layer1.weight)\n",
    "print(linear_layer1.bias)\n",
    "\n",
    "learning_rate = 0.1\n",
    "for f in linear_layer1.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "# we told the optimizer to subtract the learning rate * the gradient from our model weights\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Weights (after update):\")\n",
    "print(linear_layer1.weight)\n",
    "print(linear_layer1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pytorch's optimizer to auto update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Weights (before update):\n",
      "Parameter containing:\n",
      "tensor([[-0.2039,  0.0166, -0.2483,  0.1886]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4260], requires_grad=True)\n",
      "----------------------------------------\n",
      "Weights (after update):\n",
      "Parameter containing:\n",
      "tensor([[-0.0864,  0.2516,  0.1042,  0.6586]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3085], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Now, we're going to calculate the gradient of our loss function wrt our weights / biases\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "\n",
    "target_y = torch.tensor([0.0])\n",
    "\n",
    "predicted_y = linear_layer1(x)\n",
    "\n",
    "optimizer = optim.SGD(linear_layer1.parameters(), lr=0.1)\n",
    "# here we've created an optimizer object that's responsible for changing the weights\n",
    "# we told it which weights to change (those of our linear_layer1 model) and how much to change them (learning rate / lr)\n",
    "# but we haven't quite told it to change anything yet. First we have to calculate the gradient.\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "loss = loss_function(predicted_y, target_y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# now that we have computed the gradient, let's look at our weights before we change them:\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Weights (before update):\")\n",
    "print(linear_layer1.weight)\n",
    "print(linear_layer1.bias)\n",
    "\n",
    "optimizer.step()\n",
    "# we told the optimizer to subtract the learning rate * the gradient from our model weights\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Weights (after update):\")\n",
    "print(linear_layer1.weight)\n",
    "print(linear_layer1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5)  Updating Our Weights More Than Once (i.e. doing step 3-4 a few times aka \"epochs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Output (BEFORE UPDATE):\n",
      "tensor([-0.5876], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n",
      "Output (UPDATE 1):\n",
      "tensor([-0.2233], grad_fn=<AddBackward0>)\n",
      "Should be getting closer to 0...\n",
      "----------------------------------------\n",
      "Output (UPDATE 2):\n",
      "tensor([-0.0848], grad_fn=<AddBackward0>)\n",
      "Should be getting closer to 0...\n",
      "----------------------------------------\n",
      "Output (UPDATE 3):\n",
      "tensor([-0.0322], grad_fn=<AddBackward0>)\n",
      "Should be getting closer to 0...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# this block of code is organized a little differently than section 4, but it's mostly the same code\n",
    "# the only three differences are:\n",
    "# - The \"Hyperparameter\" constants\n",
    "# - The for loop (for helping the model do <number of epochs> training steps)\n",
    "# - The linear_layer1.zero_grad() function call on line 25. \n",
    "#   (that's just to clear the gradients in memory, since we're starting the training over each iteration/epoch)\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "target_y = torch.tensor([0.0])\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Output (BEFORE UPDATE):\")\n",
    "print(linear_layer1(x))\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3 # Number of times to update the weights\n",
    "LEARNING_RATE = 1e-2\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear_layer1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    linear_layer1.zero_grad() # Needed to clear the gradient buffer before each backprop\n",
    "    predicted_y = linear_layer1(x)\n",
    "    loss = loss_function(predicted_y, target_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Output (UPDATE \" + str(epoch + 1) + \"):\")\n",
    "    print(linear_layer1(x))\n",
    "    print(\"Should be getting closer to 0...\")\n",
    "\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6)  Making Our Epochs Only Use A Subset Of The Data (i.e. a \"minibatch\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #1):\n",
      "tensor([[-0.0085],\n",
      "        [-0.0633],\n",
      "        [-0.4495],\n",
      "        [-0.0300]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #2):\n",
      "tensor([[ 0.2904],\n",
      "        [ 0.2356],\n",
      "        [-0.0057],\n",
      "        [ 0.4198]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #1):\n",
      "tensor([[0.3562],\n",
      "        [0.4069],\n",
      "        [0.0891],\n",
      "        [0.5620]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #2):\n",
      "tensor([[0.3697],\n",
      "        [0.4204],\n",
      "        [0.1938],\n",
      "        [0.5543]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #1):\n",
      "tensor([[0.3747],\n",
      "        [0.5203],\n",
      "        [0.2358],\n",
      "        [0.6172]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #2):\n",
      "tensor([[0.3424],\n",
      "        [0.4880],\n",
      "        [0.2799],\n",
      "        [0.5379]], grad_fn=<AddmmBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.Tensor([[0.0, 0.0, 1.0, 1.0],\n",
    "                 [0.0, 1.0, 1.0, 0.0],\n",
    "                 [1.0, 0.0, 1.0, 0.0],\n",
    "                 [1.0, 1.0, 1.0, 1.0]])\n",
    "target_y = torch.Tensor([0.0, 1.0, 1.0, 0.0])\n",
    "# now, instead of having 1 data sample, we have 4 (oh yea, now we're in the big leagues)\n",
    "# but, pytorch has a DataLoader class to help us scale up, so let's use that.\n",
    "\n",
    "inputs = x # let's use the same naming convention as the pytorch documentation here\n",
    "labels = target_y # and here\n",
    "\n",
    "train = TensorDataset(inputs, labels) # here we're just putting our data samples into a tiny Tensor dataset class\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=2, shuffle=False) # and then putting the dataset above into a data loader\n",
    "# the batchsize=2 option just means that, later, when we iterate over it, we want to run our model on 2 samples at a time\n",
    "\n",
    "linear_layer1 = nn.Linear(4, 1)\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-1\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear_layer1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader): # here we split apart our data so we can run it\n",
    "        linear_layer1.zero_grad()\n",
    "        predicted_y = linear_layer1(inputs)\n",
    "#         loss = loss_function(predicted_y, labels)\n",
    "        loss = loss_function(predicted_y, labels.unsqueeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Output (UPDATE: Epoch #\" + str(epoch + 1) + \", Batch #\" + str(batch_idx + 1) + \"):\")\n",
    "        print(linear_layer1(x))\n",
    "        print(\"Should be getting closer to [0, 1, 1, 0]...\") # but some of them aren't! we need a model that fits better...\n",
    "                                                             # next up, we'll convert this model from regression to a NN\n",
    "\n",
    "print(\"----------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7)  Changing Our Model from Linear Regression to Neural Network (to make it fit the data better) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #1):\n",
      "tensor([[0.3545],\n",
      "        [0.3687],\n",
      "        [0.3595],\n",
      "        [0.3563]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #2):\n",
      "tensor([[0.3564],\n",
      "        [0.3707],\n",
      "        [0.3614],\n",
      "        [0.3582]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #1):\n",
      "tensor([[0.3585],\n",
      "        [0.3731],\n",
      "        [0.3635],\n",
      "        [0.3603]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #2):\n",
      "tensor([[0.3604],\n",
      "        [0.3751],\n",
      "        [0.3653],\n",
      "        [0.3621]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #1):\n",
      "tensor([[0.3625],\n",
      "        [0.3775],\n",
      "        [0.3674],\n",
      "        [0.3642]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #2):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.Tensor([[0.0, 0.0, 1.0, 1.0],\n",
    "                 [0.0, 1.0, 1.0, 0.0],\n",
    "                 [1.0, 0.0, 1.0, 0.0],\n",
    "                 [1.0, 1.0, 1.0, 1.0]])\n",
    "target_y = torch.Tensor([0.0, 1.0, 1.0, 0.0])\n",
    "# now, instead of having 1 data sample, we have 4 (oh yea, now we're in the big leagues)\n",
    "# but, pytorch has a DataLoader class to help us scale up, so let's use that.\n",
    "\n",
    "inputs = x # let's use the same naming convention as the pytorch documentation here\n",
    "labels = target_y # and here\n",
    "\n",
    "train = TensorDataset(inputs, labels) # here we're just putting our data samples into a tiny Tensor dataset class\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=2, shuffle=False) # and then putting the dataset above into a data loader\n",
    "# the batchsize=2 option just means that, later, when we iterate over it, we want to run our model on 2 samples at a time\n",
    "\n",
    "# Two layer Neural architecture\n",
    "linear_layer1 = nn.Linear(4, 2)\n",
    "sigmoid = nn.Sigmoid() # this is the nonlinearity that we pass the output from layers 1 and 2 into\n",
    "linear_layer2 = nn.Linear(2, 1) # this is our second layer (i.e. we're going to pass the outputs from sigmoid into here)\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 0.1\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(chain(linear_layer1.parameters(), linear_layer2.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        linear_layer1.zero_grad()\n",
    "        linear_layer2.zero_grad()\n",
    "        \n",
    "        linear_layer1_output = linear_layer1(inputs)\n",
    "        sigmoid_output = sigmoid(linear_layer1_output)\n",
    "        linear_layer2_output = linear_layer2(sigmoid_output)\n",
    "        sigmoid_output_2 = sigmoid(linear_layer2_output) # see how the output from one layer just goes into the second?\n",
    "        \n",
    "        loss = loss_function(sigmoid_output_2, labels.unsqueeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Output (UPDATE: Epoch #\" + str(epoch + 1) + \", Batch #\" + str(batch_idx + 1) + \"):\")\n",
    "        print(sigmoid(linear_layer2(sigmoid(linear_layer1(x))))) # the nested functions are getting out of hand..\n",
    "        print(\"Should be getting closer to [0, 1, 1, 0]...\") # they are if you increase the epochs amount... but it's slow!\n",
    "\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8) Abstracting our Neural Network into its PyTorch class (i.e. making it more maintainable and less messy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #1):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #1, Batch #2):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #1):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #2, Batch #2):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #1):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n",
      "Output (UPDATE: Epoch #3, Batch #2):\n",
      "tensor([[0.3643],\n",
      "        [0.3794],\n",
      "        [0.3692],\n",
      "        [0.3660]], grad_fn=<SigmoidBackward>)\n",
      "Should be getting closer to [0, 1, 1, 0]...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.Tensor([[0.0, 0.0, 1.0, 1.0],\n",
    "                 [0.0, 1.0, 1.0, 0.0],\n",
    "                 [1.0, 0.0, 1.0, 0.0],\n",
    "                 [1.0, 1.0, 1.0, 1.0]])\n",
    "target_y = torch.Tensor([0.0, 1.0, 1.0, 0.0])\n",
    "# now, instead of having 1 data sample, we have 4 (oh yea, now we're in the big leagues)\n",
    "# but, pytorch has a DataLoader class to help us scale up, so let's use that.\n",
    "\n",
    "inputs = x # let's use the same naming convention as the pytorch documentation here\n",
    "labels = target_y # and here\n",
    "\n",
    "train = TensorDataset(inputs, labels) # here we're just putting our data samples into a tiny Tensor dataset class\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=2, shuffle=False) # and then putting the dataset above into a data loader\n",
    "# the batchsize=2 option just means that, later, when we iterate over it, we want to run our model on 2 samples at a time\n",
    "\n",
    "# Two layer Neural architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 2) # here's where we define the same layers we had earlier\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x) # the forward function just sends everything through its respective layers\n",
    "        x = sigmoid(x) # including through the sigmoids after each Linear layer\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "net = Net() # we made a blueprint above for our neural network, now we initialize one.\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 0.1\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "        \n",
    "        output = net(inputs) # but now, all we have to do is pass our inputs to the neural net \n",
    "        \n",
    "        loss = loss_function(output, labels.unsqueeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Output (UPDATE: Epoch #\" + str(epoch + 1) + \", Batch #\" + str(batch_idx + 1) + \"):\")\n",
    "        print(sigmoid(linear_layer2(sigmoid(linear_layer1(x))))) # the nested functions are getting out of hand..\n",
    "        print(\"Should be getting closer to [0, 1, 1, 0]...\") # they are if you increase the epochs amount... but it's slow!\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# Awesome, so we have a neural network (nn) in the actual PyTorch Net class.\n",
    "# As it stands right now, there's tons of optimization that can be done here.\n",
    "# But, at the risk of falling for premature optimization, let's get to the end and build our full-fledged CNN first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9)  Changing Our Input From Arbitrary Vectors To Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------\n",
      "Data and labels shape for a single batch\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "----------------------------------------\n",
      "  dog  frog  deer truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In preparation for building our Convolutional Neural Network (CNN), we're going to stop using random, arbitrary vectors.\n",
    "# Instead, we're going to use an actual standardized dataset: CIFAR-10\n",
    "# We also have built in modules to help us load/wrangle the dataset, so we're going to use those too! (since we're spoiled)\n",
    "\n",
    "transform = transforms.Compose( # we're going to use this to transform our data to make each sample more uniform\n",
    "   [\n",
    "    transforms.ToTensor(), # converts each sample from a (0-255, 0-255, 0-255) PIL Image format to a (0-1, 0-1, 0-1) FloatTensor format\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # for each of the 3 channels of the image, subtract mean 0.5 and divide by stdev 0.5\n",
    "   ]) # the normalization makes each SGD iteration more stable and overall makes convergence easier\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform) # this is all we need to get/wrangle the dataset!\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # each image can have 1 of 10 labels\n",
    "\n",
    "# helper function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print('Data and labels shape for a single batch')\n",
    "print(images.shape, labels.shape)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've got a lot of boilerplate code out of the way, here's how it fits in to what we did above:\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 25) # now our first layer accepts inputs the size of the image's total information\n",
    "        self.fc2 = nn.Linear(25, 10) # Second layer has 25 hidden units\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3) # this just reshapes our tensor of image data so that we have <batch size>\n",
    "        x = self.fc1(x)             # in one dimension, and then the image data in the other\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-1\n",
    "loss_function = nn.CrossEntropyLoss() # Changing our loss / cost function to work with our labels\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Iteration: \" + str(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Awesome! Now it's trained. Time to test it:\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # just grabbing a sample from our test data set\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images)) # display the images we're going to predict\n",
    "\n",
    "outputs = net(images) # get our output from our neural network\n",
    "_, predicted = torch.max(outputs.data, 1) # get our predictions from the output\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "# print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# and let's look at the overall accuracy:\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100.0 * correct / total))\n",
    "\n",
    "# Hmm, maybe we can do better. Let's add convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11)  Adding A Convolutional Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D Layer - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's all the boilerplate again:\n",
    "transform = transforms.Compose(\n",
    "   [\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "   ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # convolve each of our 3-channel images with 6 different 5x5 kernels, giving us 6 feature maps\n",
    "        self.fc1 = nn.Linear(4704, 120) # but that results in a [Batch]x6x28x28 dimensional output, that is 4704 inputs per image.\n",
    "        self.fc2 = nn.Linear(120, 10) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = x.view(-1, 4704) # since our output from conv1 is [Batch]x6x28x28, we need to flatten it into a 4x4704 (samples x features) tensor to feed it into a linear layer\n",
    "        x = self.fc1(x)             \n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Iteration: \" + str(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holy guacamole, that takes a LOT longer. Those convolutions are expensive.\n",
    "# In the next section we'll make that a little quicker.\n",
    "# For now, let's see how much our predictions improved.\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100.0 * correct / total))\n",
    "\n",
    "# Okay... pretty good improvement. Again, before we prematurely optimize, let's add some pooling layers to make it quicker.\n",
    "# THEN we'll go ham on the optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12)  Adding A Pooling Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling Layer - https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and again, boilerplate:\n",
    "transform = transforms.Compose(\n",
    "   [\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "   ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # The output of Conv2d is [Batch]x6x28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2) # in any 2x2 square on each of our feature maps, take the most important (highest) one\n",
    "        # The output of MaxPool2d is of shape [Batch]x6x14x14\n",
    "        self.fc1 = nn.Linear(1176, 120) # since we've pooled our outputs from the convolution, tour input is reduced: 4704 -> 1176\n",
    "        self.fc2 = nn.Linear(120, 10) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x) # returns x of size: torch.Size([4, 6, 28, 28])\n",
    "        x = self.pool(x) # returns x of size: torch.Size([4, 6, 14, 14]) (so we have to adjust our linear input again)\n",
    "        x = x.view(-1, 1176) # now our input to the linear layer is going to be 4 by 6 * 14 * 14 = 1176\n",
    "        x = self.fc1(x)             \n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "NUMBER_OF_EPOCHS = 3\n",
    "LEARNING_RATE = 1e-1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Iteration: \" + str(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty significant speedup! Let's see how it affects accuracy:\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100.0 * correct / total))\n",
    "\n",
    "# Not by much! Awesome!\n",
    "# Now, let's add a few more layers, change our nonlinearities around, and do some other house keeping:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13) Homework - Do Some Final Optimizations (i.e. making our first sigmoid a \"ReLU\",  and adding more layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "   [\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "   ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5) # Let's add more feature maps - that might help\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5) # And another conv layer with even more feature maps\n",
    "        self.fc1 = nn.Linear(20 * 5 * 5, 120) # and finally, adjusting our first linear layer's input to our previous output\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) # we're changing our nonlinearity / activation function from sigmoid to ReLU for a slight speedup\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x) # after this pooling layer, we're down to a torch.Size([4, 20, 5, 5]) tensor.\n",
    "        x = x.view(-1, 20 * 5 * 5) # so let's adjust our tensor again.\n",
    "        x = self.fc1(x)             \n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "# net = Net()\n",
    "net = Net().cuda() # Let's make our NN run on the GPU (I didn't splurge on this GTX 1080 for nothing...)\n",
    "\n",
    "NUMBER_OF_EPOCHS = 25 # Let's also increase our training cycles\n",
    "LEARNING_RATE = 1e-2 # And decrease our learning rate a little bit to compensate\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "#         inputs, labels = inputs.cuda(), labels.cuda() # Let's also make these tensors GPU compatible\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Iteration: \" + str(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "outputs = net(images.cuda())\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    inputs = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# Awesome! A lot better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14)  Bask... in the glory that is our newly created Convolutional Neural Network (CNN)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awesome - we have a full blown convolutional neural network!\n",
    "# Let's condense some stuff and put it all together without comments:\n",
    "\n",
    "transform = transforms.Compose(\n",
    "   [\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "   ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc1 = nn.Linear(20 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 5 * 5)           \n",
    "        x = F.relu(self.fc1(x) )\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net().cuda()\n",
    "\n",
    "NUMBER_OF_EPOCHS = 25\n",
    "LEARNING_RATE = 1e-2\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        net.zero_grad()\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = net(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 5 is 0:\n",
    "        print(\"Iteration: \" + str(epoch + 1))\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "outputs = net(images.cuda())\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    labels = labels.cuda()\n",
    "    outputs = net(images.cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
